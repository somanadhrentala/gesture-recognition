{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from imageio import imread\n",
    "from PIL import Image\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "train_doc = np.random.permutation(open('/home/datasets/Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('/home/datasets/Project_data/val.csv').readlines())\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from imageio import imread  # Make sure scipy is installed as mentioned\n",
    "from PIL import Image\n",
    "import cv2  # For image processing\n",
    "\n",
    "def generator(source_path, folder_list, batch_size):\n",
    "    print('Source path =', source_path, '; batch size =', batch_size)\n",
    "    img_idx = list(range(0, 30))\n",
    "    # Get number of batches\n",
    "    num_batches = len(folder_list) // batch_size\n",
    "    x = 30\n",
    "    y = 180\n",
    "    z = 180\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)  # Shuffle the folder list\n",
    "        \n",
    "        for batch in range(num_batches):  # Iterate over the number of batches\n",
    "            batch_data = np.zeros((batch_size, x, y, z, 3))  # Create a placeholder for batch data (x, y, z, 3 channels)\n",
    "            batch_labels = np.zeros((batch_size, 5))  # One-hot encoded labels (for 5 classes)\n",
    "\n",
    "            for folder in range(batch_size):  # Iterate over the batch_size\n",
    "                folder_path = os.path.join(source_path, t[folder + (batch * batch_size)].split(';')[0])\n",
    "                imgs = os.listdir(folder_path)  # Read all images in the folder\n",
    "                \n",
    "                # Iterate over the frames/images in the folder (based on `img_idx`)\n",
    "                for idx, item in enumerate(img_idx):\n",
    "                    image = imread(os.path.join(folder_path, imgs[item])).astype(np.float32)\n",
    "\n",
    "                    # Crop and resize images to ensure consistent shape (y, z)\n",
    "                    image = cv2.resize(image, (z, y))  # Resize to (y, z) shape, ensure the right shape for Conv3D\n",
    "\n",
    "                    # Normalize and feed in the image\n",
    "                    batch_data[folder, idx, :, :, 0] = image[:, :, 0] / 255.0  # Normalize RGB channels\n",
    "                    batch_data[folder, idx, :, :, 1] = image[:, :, 1] / 255.0\n",
    "                    batch_data[folder, idx, :, :, 2] = image[:, :, 2] / 255.0\n",
    "\n",
    "                # Assign label (one-hot encoding)\n",
    "                label_index = int(t[folder + (batch * batch_size)].strip().split(';')[2])\n",
    "                batch_labels[folder, label_index] = 1\n",
    "            \n",
    "            yield batch_data, batch_labels  # Yield the batch data and labels\n",
    "\n",
    "        # Handle the remaining data points after full batches\n",
    "        remaining_samples = len(folder_list) % batch_size\n",
    "        if remaining_samples > 0:\n",
    "            batch_data = np.zeros((remaining_samples, x, y, z, 3))\n",
    "            batch_labels = np.zeros((remaining_samples, 5))\n",
    "\n",
    "            for folder in range(remaining_samples):\n",
    "                folder_path = os.path.join(source_path, t[folder + (num_batches * batch_size)].split(';')[0])\n",
    "                imgs = os.listdir(folder_path)\n",
    "\n",
    "                for idx, item in enumerate(img_idx):\n",
    "                    image = imread(os.path.join(folder_path, imgs[item])).astype(np.float32)\n",
    "\n",
    "                    # Crop and resize images to ensure consistent shape (y, z)\n",
    "                    image = cv2.resize(image, (z, y))\n",
    "\n",
    "                    # Normalize and feed in the image\n",
    "                    batch_data[folder, idx, :, :, 0] = image[:, :, 0] / 255.0\n",
    "                    batch_data[folder, idx, :, :, 1] = image[:, :, 1] / 255.0\n",
    "                    batch_data[folder, idx, :, :, 2] = image[:, :, 2] / 255.0\n",
    "\n",
    "                # Assign label (one-hot encoding)\n",
    "                label_index = int(t[folder + (num_batches * batch_size)].strip().split(';')[2])\n",
    "                batch_labels[folder, label_index] = 1\n",
    "\n",
    "            yield batch_data, batch_labels  # Yield the remaining batch data and labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 30\n"
     ]
    }
   ],
   "source": [
    "curr_dt_time = datetime.datetime.now()\n",
    "train_path = '/home/datasets/Project_data/train'\n",
    "val_path = '/home/datasets/Project_data/val'\n",
    "num_train_sequences = len(train_doc)\n",
    "print('# training sequences =', num_train_sequences)\n",
    "num_val_sequences = len(val_doc)\n",
    "print('# validation sequences =', num_val_sequences)\n",
    "num_epochs = 30\n",
    "print ('# epochs =', num_epochs)\n",
    "\n",
    "# Hyperparameters\n",
    "img_size = (180, 180)  # Resize images\n",
    "frames = 30  # Number of frames per sequence\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, GRU, Dense, Dropout, TimeDistributed, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import SpatialDropout2D\n",
    "\n",
    "\n",
    "def cnn_rnn_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape[1:])\n",
    "    base_model.trainable = False  # Freeze ResNet50 to prevent overfitting initially\n",
    "    \n",
    "\n",
    "    model.add(TimeDistributed(base_model, input_shape=input_shape))\n",
    "    model.add(TimeDistributed(SpatialDropout2D(0.3)))\n",
    "    model.add(TimeDistributed(Flatten()))  \n",
    "\n",
    "    model.add(GRU(32, return_sequences=False, activation='relu'))\n",
    "    model.add(Dropout(0.5)) \n",
    "\n",
    "   \n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(num_classes, activation='softmax'))  \n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    return model\n",
    "\n",
    "model = cnn_rnn_model(input_shape=(30, 180, 180, 3), num_classes=5)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications import MobileNetV2\n",
    "# from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# def create_model(input_shape, num_classes):\n",
    "#     base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=input_shape[1:])\n",
    "#     base_model.trainable = False  # Freeze layers\n",
    "\n",
    "#     model = Sequential([\n",
    "#         TimeDistributed(base_model, input_shape=input_shape),\n",
    "#         TimeDistributed(Flatten()),\n",
    "#         GRU(16, return_sequences=False),\n",
    "#         Dense(num_classes, activation='softmax')\n",
    "#     ])\n",
    "#     model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    \n",
    "#     return model\n",
    "# model = create_model(input_shape=(30, 180, 180, 3), num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_6 (TimeDis  (None, 30, 6, 6, 1280)   2257984   \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_7 (TimeDis  (None, 30, 6, 6, 1280)   0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_8 (TimeDis  (None, 30, 46080)        0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 32)                4426944   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,686,277\n",
      "Trainable params: 4,428,229\n",
      "Non-trainable params: 2,258,048\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "\n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "\n",
    "# filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{accuracy:.5f}-{val_loss:.5f}-{val_accuracy:.5f}.keras'\n",
    "\n",
    "filepath = model_name + \"model{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.keras\"\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', save_freq='epoch')\n",
    "\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss',  \n",
    "                       factor=0.5,           \n",
    "                       patience=5,           \n",
    "                       verbose=1,            \n",
    "                       min_lr=1e-6)          \n",
    "\n",
    "callbacks_list = [checkpoint, LR, early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path = /home/datasets/Project_data/train ; batch size = 32\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.2796 - categorical_accuracy: 0.2157Source path = /home/datasets/Project_data/val ; batch size = 32\n",
      "\n",
      "Epoch 00001: saving model to model_init_2025-03-0316_18_51.841788/model00001-2.27965-0.21569-2.79084-0.16000.keras\n",
      "21/21 [==============================] - 87s 4s/step - loss: 2.2796 - categorical_accuracy: 0.2157 - val_loss: 2.7908 - val_categorical_accuracy: 0.1600 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.2054 - categorical_accuracy: 0.2112\n",
      "Epoch 00002: saving model to model_init_2025-03-0316_18_51.841788/model00002-2.20545-0.21116-1.60139-0.30000.keras\n",
      "21/21 [==============================] - 77s 4s/step - loss: 2.2054 - categorical_accuracy: 0.2112 - val_loss: 1.6014 - val_categorical_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.9891 - categorical_accuracy: 0.2579\n",
      "Epoch 00003: saving model to model_init_2025-03-0316_18_51.841788/model00003-1.98907-0.25792-1.36402-0.50000.keras\n",
      "21/21 [==============================] - 78s 4s/step - loss: 1.9891 - categorical_accuracy: 0.2579 - val_loss: 1.3640 - val_categorical_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.9561 - categorical_accuracy: 0.2549\n",
      "Epoch 00004: saving model to model_init_2025-03-0316_18_51.841788/model00004-1.95610-0.25490-1.38947-0.43000.keras\n",
      "21/21 [==============================] - 83s 4s/step - loss: 1.9561 - categorical_accuracy: 0.2549 - val_loss: 1.3895 - val_categorical_accuracy: 0.4300 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7875 - categorical_accuracy: 0.2911\n",
      "Epoch 00005: saving model to model_init_2025-03-0316_18_51.841788/model00005-1.78748-0.29110-1.36496-0.41000.keras\n",
      "21/21 [==============================] - 78s 4s/step - loss: 1.7875 - categorical_accuracy: 0.2911 - val_loss: 1.3650 - val_categorical_accuracy: 0.4100 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7812 - categorical_accuracy: 0.2851\n",
      "Epoch 00006: saving model to model_init_2025-03-0316_18_51.841788/model00006-1.78116-0.28507-1.23381-0.62000.keras\n",
      "21/21 [==============================] - 79s 4s/step - loss: 1.7812 - categorical_accuracy: 0.2851 - val_loss: 1.2338 - val_categorical_accuracy: 0.6200 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7302 - categorical_accuracy: 0.3228\n",
      "Epoch 00007: saving model to model_init_2025-03-0316_18_51.841788/model00007-1.73022-0.32278-1.38877-0.46000.keras\n",
      "21/21 [==============================] - 78s 4s/step - loss: 1.7302 - categorical_accuracy: 0.3228 - val_loss: 1.3888 - val_categorical_accuracy: 0.4600 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.6063 - categorical_accuracy: 0.3273\n",
      "Epoch 00008: saving model to model_init_2025-03-0316_18_51.841788/model00008-1.60631-0.32730-1.12528-0.63000.keras\n",
      "21/21 [==============================] - 77s 4s/step - loss: 1.6063 - categorical_accuracy: 0.3273 - val_loss: 1.1253 - val_categorical_accuracy: 0.6300 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.4908 - categorical_accuracy: 0.3891\n",
      "Epoch 00009: saving model to model_init_2025-03-0316_18_51.841788/model00009-1.49076-0.38914-1.07669-0.76000.keras\n",
      "21/21 [==============================] - 78s 4s/step - loss: 1.4908 - categorical_accuracy: 0.3891 - val_loss: 1.0767 - val_categorical_accuracy: 0.7600 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.3707 - categorical_accuracy: 0.4374\n",
      "Epoch 00010: saving model to model_init_2025-03-0316_18_51.841788/model00010-1.37071-0.43741-1.04641-0.68000.keras\n",
      "21/21 [==============================] - 78s 4s/step - loss: 1.3707 - categorical_accuracy: 0.4374 - val_loss: 1.0464 - val_categorical_accuracy: 0.6800 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.2872 - categorical_accuracy: 0.4661\n",
      "Epoch 00011: saving model to model_init_2025-03-0316_18_51.841788/model00011-1.28723-0.46606-1.02659-0.61000.keras\n",
      "21/21 [==============================] - 85s 4s/step - loss: 1.2872 - categorical_accuracy: 0.4661 - val_loss: 1.0266 - val_categorical_accuracy: 0.6100 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.2026 - categorical_accuracy: 0.5068\n",
      "Epoch 00012: saving model to model_init_2025-03-0316_18_51.841788/model00012-1.20262-0.50679-1.04703-0.71000.keras\n",
      "21/21 [==============================] - 78s 4s/step - loss: 1.2026 - categorical_accuracy: 0.5068 - val_loss: 1.0470 - val_categorical_accuracy: 0.7100 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.1519 - categorical_accuracy: 0.5143\n",
      "Epoch 00013: saving model to model_init_2025-03-0316_18_51.841788/model00013-1.15188-0.51433-0.92594-0.77000.keras\n",
      "21/21 [==============================] - 78s 4s/step - loss: 1.1519 - categorical_accuracy: 0.5143 - val_loss: 0.9259 - val_categorical_accuracy: 0.7700 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.1170 - categorical_accuracy: 0.5505\n",
      "Epoch 00014: saving model to model_init_2025-03-0316_18_51.841788/model00014-1.11704-0.55053-0.92691-0.75000.keras\n",
      "21/21 [==============================] - 79s 4s/step - loss: 1.1170 - categorical_accuracy: 0.5505 - val_loss: 0.9269 - val_categorical_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.0694 - categorical_accuracy: 0.5686\n",
      "Epoch 00015: saving model to model_init_2025-03-0316_18_51.841788/model00015-1.06944-0.56863-0.90480-0.76000.keras\n",
      "21/21 [==============================] - 81s 4s/step - loss: 1.0694 - categorical_accuracy: 0.5686 - val_loss: 0.9048 - val_categorical_accuracy: 0.7600 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.1282 - categorical_accuracy: 0.5490\n",
      "Epoch 00016: saving model to model_init_2025-03-0316_18_51.841788/model00016-1.12819-0.54902-0.82686-0.81000.keras\n",
      "21/21 [==============================] - 75s 4s/step - loss: 1.1282 - categorical_accuracy: 0.5490 - val_loss: 0.8269 - val_categorical_accuracy: 0.8100 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.0058 - categorical_accuracy: 0.6094\n",
      "Epoch 00017: saving model to model_init_2025-03-0316_18_51.841788/model00017-1.00581-0.60935-0.72221-0.84000.keras\n",
      "21/21 [==============================] - 80s 4s/step - loss: 1.0058 - categorical_accuracy: 0.6094 - val_loss: 0.7222 - val_categorical_accuracy: 0.8400 - lr: 0.0010\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.9624 - categorical_accuracy: 0.6229\n",
      "Epoch 00018: saving model to model_init_2025-03-0316_18_51.841788/model00018-0.96235-0.62293-0.82509-0.74000.keras\n",
      "21/21 [==============================] - 79s 4s/step - loss: 0.9624 - categorical_accuracy: 0.6229 - val_loss: 0.8251 - val_categorical_accuracy: 0.7400 - lr: 0.0010\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.9225 - categorical_accuracy: 0.6410\n",
      "Epoch 00019: saving model to model_init_2025-03-0316_18_51.841788/model00019-0.92253-0.64103-0.73622-0.85000.keras\n",
      "21/21 [==============================] - 80s 4s/step - loss: 0.9225 - categorical_accuracy: 0.6410 - val_loss: 0.7362 - val_categorical_accuracy: 0.8500 - lr: 0.0010\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.8529 - categorical_accuracy: 0.6697\n",
      "Epoch 00020: saving model to model_init_2025-03-0316_18_51.841788/model00020-0.85295-0.66968-0.73714-0.73000.keras\n",
      "21/21 [==============================] - 77s 4s/step - loss: 0.8529 - categorical_accuracy: 0.6697 - val_loss: 0.7371 - val_categorical_accuracy: 0.7300 - lr: 0.0010\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.8632 - categorical_accuracy: 0.7044\n",
      "Epoch 00021: saving model to model_init_2025-03-0316_18_51.841788/model00021-0.86322-0.70437-0.75505-0.77000.keras\n",
      "21/21 [==============================] - 79s 4s/step - loss: 0.8632 - categorical_accuracy: 0.7044 - val_loss: 0.7550 - val_categorical_accuracy: 0.7700 - lr: 0.0010\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.8093 - categorical_accuracy: 0.7029\n",
      "Epoch 00022: saving model to model_init_2025-03-0316_18_51.841788/model00022-0.80934-0.70287-0.63665-0.79000.keras\n",
      "21/21 [==============================] - 78s 4s/step - loss: 0.8093 - categorical_accuracy: 0.7029 - val_loss: 0.6366 - val_categorical_accuracy: 0.7900 - lr: 0.0010\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.7745 - categorical_accuracy: 0.7436\n",
      "Epoch 00023: saving model to model_init_2025-03-0316_18_51.841788/model00023-0.77452-0.74359-0.67785-0.80000.keras\n",
      "21/21 [==============================] - 79s 4s/step - loss: 0.7745 - categorical_accuracy: 0.7436 - val_loss: 0.6779 - val_categorical_accuracy: 0.8000 - lr: 0.0010\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.7470 - categorical_accuracy: 0.7360\n",
      "Epoch 00024: saving model to model_init_2025-03-0316_18_51.841788/model00024-0.74700-0.73605-0.64558-0.82000.keras\n",
      "21/21 [==============================] - 76s 4s/step - loss: 0.7470 - categorical_accuracy: 0.7360 - val_loss: 0.6456 - val_categorical_accuracy: 0.8200 - lr: 0.0010\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.7656 - categorical_accuracy: 0.7421\n",
      "Epoch 00025: saving model to model_init_2025-03-0316_18_51.841788/model00025-0.76564-0.74208-0.59341-0.81000.keras\n",
      "21/21 [==============================] - 77s 4s/step - loss: 0.7656 - categorical_accuracy: 0.7421 - val_loss: 0.5934 - val_categorical_accuracy: 0.8100 - lr: 0.0010\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.6981 - categorical_accuracy: 0.7813\n",
      "Epoch 00026: saving model to model_init_2025-03-0316_18_51.841788/model00026-0.69814-0.78130-0.60783-0.78000.keras\n",
      "21/21 [==============================] - 77s 4s/step - loss: 0.6981 - categorical_accuracy: 0.7813 - val_loss: 0.6078 - val_categorical_accuracy: 0.7800 - lr: 0.0010\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.7157 - categorical_accuracy: 0.7541\n",
      "Epoch 00027: saving model to model_init_2025-03-0316_18_51.841788/model00027-0.71574-0.75415-0.61135-0.81000.keras\n",
      "21/21 [==============================] - 77s 4s/step - loss: 0.7157 - categorical_accuracy: 0.7541 - val_loss: 0.6114 - val_categorical_accuracy: 0.8100 - lr: 0.0010\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.6317 - categorical_accuracy: 0.7798\n",
      "Epoch 00028: saving model to model_init_2025-03-0316_18_51.841788/model00028-0.63167-0.77979-0.63049-0.76000.keras\n",
      "21/21 [==============================] - 76s 4s/step - loss: 0.6317 - categorical_accuracy: 0.7798 - val_loss: 0.6305 - val_categorical_accuracy: 0.7600 - lr: 0.0010\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.6309 - categorical_accuracy: 0.8115\n",
      "Epoch 00029: saving model to model_init_2025-03-0316_18_51.841788/model00029-0.63095-0.81146-0.55216-0.84000.keras\n",
      "21/21 [==============================] - 78s 4s/step - loss: 0.6309 - categorical_accuracy: 0.8115 - val_loss: 0.5522 - val_categorical_accuracy: 0.8400 - lr: 0.0010\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.6574 - categorical_accuracy: 0.7768\n",
      "Epoch 00030: saving model to model_init_2025-03-0316_18_51.841788/model00030-0.65738-0.77677-0.60724-0.79000.keras\n",
      "21/21 [==============================] - 78s 4s/step - loss: 0.6574 - categorical_accuracy: 0.7768 - val_loss: 0.6072 - val_categorical_accuracy: 0.7900 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe2705e8f40>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_generator,                \n",
    "    steps_per_epoch=steps_per_epoch, \n",
    "    epochs=num_epochs,              \n",
    "    verbose=1,                        \n",
    "    callbacks=callbacks_list,        \n",
    "    validation_data=val_generator,   \n",
    "    validation_steps=validation_steps                \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 113s 3s/step - loss: 0.5560 - categorical_accuracy: 0.8130\n",
      "evaluate categorical_accuracy: 81.30%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(val_generator, \n",
    "verbose=1, \n",
    "steps=validation_steps*10, \n",
    "max_queue_size=3000, \n",
    "workers=1, \n",
    "use_multiprocessing=False)\n",
    "print(\"%s%s: %.2f%%\" % (\"evaluate \",model.metrics_names[1], scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
